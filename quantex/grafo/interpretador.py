"""
Interpretador de Consultas - Sistema Grafo
VersiÃ³n 1.0 - InterpretaciÃ³n inteligente de preguntas del usuario
"""

import os
import sys
import json
import traceback
from typing import Dict, Any, Optional

# Agregar Quantex al path
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)

from quantex.core.ai_services import ai_services
from quantex.core import llm_manager

class ConsultaInterpretador:
    """
    Interpreta consultas del usuario y las convierte en bÃºsquedas optimizadas
    """
    
    def __init__(self):
        self.ai_services = ai_services
        self.llm_manager = llm_manager
        
        # Cargar prompt del interpretador
        self.prompt_template = self._load_prompt()
    
    def _load_prompt(self) -> str:
        """Carga el prompt del interpretador"""
        try:
            prompt_path = os.path.join(os.path.dirname(__file__), 'prompts', 'interpretador.txt')
            with open(prompt_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            print(f"âš ï¸ Error cargando prompt del interpretador: {e}")
            return "Analiza la consulta del usuario y determina quÃ© informaciÃ³n necesita del grafo de conocimiento."
    
    def interpretar_consulta(self, consulta: str) -> Dict[str, Any]:
        """
        Interpreta una consulta del usuario y determina la estrategia de bÃºsqueda
        
        Args:
            consulta: Pregunta o consulta del usuario
            
        Returns:
            Diccionario con la interpretaciÃ³n estructurada
        """
        try:
            print(f"ğŸ§  [Interpretador] Analizando consulta: '{consulta[:50]}...'")
            
            # Usar LLM para interpretar la consulta
            response = self.llm_manager.generate_structured_output(
                system_prompt=self.prompt_template,
                user_prompt=f"Consulta del usuario: '{consulta}'",
                model_name="claude-3-haiku-20240307",
                output_schema={
                    "type": "object",
                    "properties": {
                        "categoria": {"type": "string"},
                        "conceptos_clave": {"type": "array", "items": {"type": "string"}},
                        "consulta_reformulada": {"type": "string"},
                        "filtro_temporal": {"type": ["string", "null"]},
                        "necesita_sintesis": {"type": "boolean"},
                        "confianza": {"type": "number", "minimum": 0.0, "maximum": 1.0}
                    },
                    "required": ["categoria", "conceptos_clave", "consulta_reformulada", "necesita_sintesis", "confianza"]
                }
            )
            
            # Validar y limpiar respuesta
            interpretacion = self._validar_interpretacion(response)
            
            print(f"âœ… [Interpretador] CategorÃ­a: {interpretacion['categoria']}, Confianza: {interpretacion['confianza']:.2f}")
            
            return interpretacion
            
        except Exception as e:
            print(f"âŒ [Interpretador] Error interpretando consulta: {e}")
            traceback.print_exc()
            
            # Fallback: interpretaciÃ³n bÃ¡sica
            return self._interpretacion_fallback(consulta)
    
    def _validar_interpretacion(self, response: Dict[str, Any]) -> Dict[str, Any]:
        """Valida y limpia la interpretaciÃ³n del LLM"""
        try:
            # Asegurar que todos los campos requeridos estÃ©n presentes
            interpretacion = {
                "categoria": response.get("categoria", "ANÃLISIS_TEMÃTICO"),
                "conceptos_clave": response.get("conceptos_clave", []),
                "consulta_reformulada": response.get("consulta_reformulada", ""),
                "filtro_temporal": response.get("filtro_temporal"),
                "necesita_sintesis": response.get("necesita_sintesis", True),
                "confianza": float(response.get("confianza", 0.7))
            }
            
            # Limpiar consulta reformulada
            if not interpretacion["consulta_reformulada"]:
                interpretacion["consulta_reformulada"] = interpretacion["conceptos_clave"][0] if interpretacion["conceptos_clave"] else ""
            
            # Validar confianza
            interpretacion["confianza"] = max(0.0, min(1.0, interpretacion["confianza"]))
            
            return interpretacion
            
        except Exception as e:
            print(f"âš ï¸ Error validando interpretaciÃ³n: {e}")
            return self._interpretacion_fallback("")
    
    def _interpretacion_fallback(self, consulta: str) -> Dict[str, Any]:
        """InterpretaciÃ³n de fallback cuando falla el LLM"""
        print("ğŸ”„ [Interpretador] Usando interpretaciÃ³n de fallback")
        
        consulta_lower = consulta.lower()
        
        # DetecciÃ³n bÃ¡sica de categorÃ­as
        if any(word in consulta_lower for word in ["cÃ³mo", "como", "relaciona", "conecta", "impacto"]):
            categoria = "CONEXIONES"
        elif any(word in consulta_lower for word in ["reciente", "Ãºltimo", "hoy", "ayer"]):
            categoria = "TEMPORAL"
        elif any(word in consulta_lower for word in ["por quÃ©", "porque", "causa", "motivo"]):
            categoria = "CAUSAL"
        elif any(word in consulta_lower for word in ["quÃ© pasarÃ­a", "que pasaria", "tendencia", "predicciÃ³n"]):
            categoria = "PREDICTIVO"
        else:
            categoria = "ANÃLISIS_TEMÃTICO"
        
        # Extraer conceptos clave bÃ¡sicos
        conceptos = []
        palabras_importantes = ["cobre", "clp", "dÃ³lar", "dolar", "fed", "inflaciÃ³n", "inflacion", "tasa", "mercado", "china", "usa"]
        for palabra in palabras_importantes:
            if palabra in consulta_lower:
                conceptos.append(palabra)
        
        return {
            "categoria": categoria,
            "conceptos_clave": conceptos,
            "consulta_reformulada": consulta,
            "filtro_temporal": None,
            "necesita_sintesis": True,
            "confianza": 0.5
        }
    
    def detectar_intencion_grafo(self, consulta: str) -> bool:
        """
        Detecta si la consulta estÃ¡ dirigida al grafo de conocimiento
        
        Args:
            consulta: Consulta del usuario
            
        Returns:
            True si la consulta es para el grafo
        """
        consulta_lower = consulta.lower()
        
        # Keywords que indican consulta al grafo
        grafo_keywords = [
            'quÃ© sÃ© sobre', 'quÃ© conozco de', 'quÃ© informaciÃ³n tengo',
            'buscar en mi conocimiento', 'explorar mi conocimiento',
            'quÃ© documentos tengo', 'quÃ© datos tengo',
            'cÃ³mo se relaciona', 'quÃ© conexiones hay',
            'grafo de conocimiento', 'mi conocimiento',
            'quÃ© anÃ¡lisis tengo', 'quÃ© reportes tengo',
            'informaciÃ³n sobre', 'datos sobre',
            'quÃ© noticias', 'quÃ© anÃ¡lisis tÃ©cnico', 'quÃ© anÃ¡lisis',
            'cÃ³mo estÃ¡', 'estado de', 'situaciÃ³n de',
            'quÃ© tengo sobre', 'quÃ© conozco sobre',
            'informaciÃ³n de', 'anÃ¡lisis de', 'reportes de',
            # NUEVAS: Consultas especÃ­ficas (SIN comandos de herramientas)
            'buscame', 'muestrame', 'dame',
            'noticias de', 'noticias del', 'noticias sobre',
            'ultimos', 'Ãºltimos', 'dias', 'dÃ­as',
            'smm', 'mktnews', 'autonomous',
            'de la semana', 'de esta semana', 'de hoy',
            'todos', 'todas', 'todas las'
        ]
        
        return any(keyword in consulta_lower for keyword in grafo_keywords)

# Instancia global del interpretador
_interpretador = None

def get_interpretador() -> ConsultaInterpretador:
    """Obtiene la instancia global del interpretador"""
    global _interpretador
    if _interpretador is None:
        _interpretador = ConsultaInterpretador()
    return _interpretador

if __name__ == "__main__":
    # Prueba del interpretador
    print("ğŸ§ª Probando Interpretador de Consultas...")
    
    interpretador = ConsultaInterpretador()
    
    # Pruebas
    consultas_prueba = [
        "Â¿QuÃ© sÃ© sobre el cobre?",
        "Â¿CÃ³mo se relaciona la inflaciÃ³n con las tasas de interÃ©s?",
        "Â¿QuÃ© noticias recientes hay sobre China?",
        "Â¿Por quÃ© subiÃ³ el precio del cobre?"
    ]
    
    for consulta in consultas_prueba:
        print(f"\nğŸ” Consulta: {consulta}")
        resultado = interpretador.interpretar_consulta(consulta)
        print(f"ğŸ“Š Resultado: {resultado['categoria']} - {resultado['consulta_reformulada']}")
